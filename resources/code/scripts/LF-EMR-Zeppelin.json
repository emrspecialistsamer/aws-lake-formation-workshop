{"paragraphs":[{"text":"In Lake Formation enabled clusters, Spark SQL can only read from data managed by AWS Glue Data Catalog and cannot access data managed outside of AWS Glue or Lake Formation.\nData from other sources can be accessed using non-Spark SQL operations if the IAM role for other AWS Services chosen during cluster deployment has policies in place allowing the cluster to access those data sources\n\nSpark SQL can only read from Lake Formation tables\n\nSo let's see how may databases you have access to, one of them should be tpc as SAML authenticatd user has SELECT permission for two of the tables in tpc database.","user":"smunigati","dateUpdated":"2020-02-12T21:39:29+0000","config":{"colWidth":12,"fontSize":9,"enabled":false,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1581543496589_899979851","id":"20200212-213816_325620074","dateCreated":"2020-02-12T21:38:16+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3466"},{"title":"","text":"spark.sql(\"show databases\").show()","user":"smunigati","dateUpdated":"2020-02-12T17:20:46+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------------+\n|databaseName|\n+------------+\n|     default|\n|    sampledb|\n|         tpc|\n+------------+"},{"type":"HTML","data":"<hr/>Spark Application Id: application_1581349405431_0004<br/>Spark WebUI: <a href=\"http://ip-10-0-1-103.ec2.internal:20888/proxy/application_1581349405431_0004/\">http://ip-10-0-1-103.ec2.internal:20888/proxy/application_1581349405431_0004/</a>"}]},"apps":[],"jobName":"paragraph_1581365638511_-1778161508","id":"20200210-201358_1488794384","dateCreated":"2020-02-10T20:13:58+0000","dateStarted":"2020-02-12T17:20:46+0000","dateFinished":"2020-02-12T17:20:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3467"},{"text":"As we gave SELECT permission to dl_tpc_web_page table under tpc database , let's get the count(*) of rows from the table ","user":"smunigati","dateUpdated":"2020-02-12T21:40:27+0000","config":{"colWidth":12,"fontSize":9,"enabled":false,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1581543587100_438552754","id":"20200212-213947_706265815","dateCreated":"2020-02-12T21:39:47+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:3468"},{"text":"spark.sql( \"select count(*) from tpc.dl_tpc_web_page \").show()","user":"smunigati","dateUpdated":"2020-02-12T17:20:49+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"count(1)":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}},"helium":{}}},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+\n|count(1)|\n+--------+\n|    3600|\n+--------+"},{"type":"HTML","data":"<hr/>Spark Application Id: application_1581349405431_0004<br/>Spark WebUI: <a href=\"http://ip-10-0-1-103.ec2.internal:20888/proxy/application_1581349405431_0004/\">http://ip-10-0-1-103.ec2.internal:20888/proxy/application_1581349405431_0004/</a>"}]},"apps":[],"jobName":"paragraph_1581366377105_-1917801899","id":"20200210-202617_1512789887","dateCreated":"2020-02-10T20:26:17+0000","dateStarted":"2020-02-12T17:20:49+0000","dateFinished":"2020-02-12T17:20:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3469"},{"text":"spark.sql( \" SELECT sum(ws_net_paid_inc_tax) NetPaid, ws_web_site_sk WebSiteID FROM tpc.dl_tpc_web_sales ws, tpc.dl_tpc_web_page wp WHERE ws.ws_web_site_sk =wp.wp_web_page_sk GROUP BY  ws_web_site_sk \").show()","user":"smunigati","dateUpdated":"2020-02-11T13:50:19+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"NetPaid":"string","WebSiteID":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----------+---------+\n|    NetPaid|WebSiteID|\n+-----------+---------+\n|25270749.33|        1|\n|24409352.92|        2|\n|24823169.90|        4|\n|25445390.34|        7|\n|25811585.40|        8|\n|25024877.60|       10|\n|25046976.36|       13|\n|24986231.12|       14|\n|24518423.73|       16|\n|24924972.15|       19|\n|25781409.47|       20|\n|25448611.17|       22|\n|25611532.61|       25|\n|25421459.92|       26|\n|25727733.44|       28|\n|25516118.29|       31|\n|25978611.48|       32|\n|24996325.31|       34|\n|24764737.96|       37|\n|25709251.40|       38|\n+-----------+---------+\nonly showing top 20 rows"},{"type":"HTML","data":"<hr/>Spark Application Id: application_1581349405431_0003<br/>Spark WebUI: <a href=\"http://ip-10-0-1-103.ec2.internal:20888/proxy/application_1581349405431_0003/\">http://ip-10-0-1-103.ec2.internal:20888/proxy/application_1581349405431_0003/</a>"}]},"apps":[],"jobName":"paragraph_1581368830356_-1933527107","id":"20200210-210710_1556991954","dateCreated":"2020-02-10T21:07:10+0000","dateStarted":"2020-02-11T13:50:19+0000","dateFinished":"2020-02-11T13:50:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3470"},{"text":"Let's select a table for which user does not have SELECT permission and see what happens? You should receive Service: AWSGlue; Status Code: 400; Error Code: AccessDeniedException for the following","user":"smunigati","dateUpdated":"2020-02-12T21:41:42+0000","config":{"colWidth":12,"fontSize":9,"enabled":false,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1581543680308_-1229098585","id":"20200212-214120_529407211","dateCreated":"2020-02-12T21:41:20+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:3471"},{"text":"%sql\nSELECT * FROM tpc.dl_tpc_item limit 10","user":"smunigati","dateUpdated":"2020-02-11T13:47:48+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"org.apache.spark.sql.AnalysisException: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to fetch table dl_tpc_item. Insufficient Lake Formation permission(s) on dl_tpc_item (Service: AWSGlue; Status Code: 400; Error Code: AccessDeniedException; Request ID: d22c3162-f033-4ccb-bc9e-7ded70c67987);\n  at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:106)\n  at org.apache.spark.sql.hive.HiveExternalCatalog.tableExists(HiveExternalCatalog.scala:824)\n  at org.apache.spark.sql.catalyst.catalog.ExternalCatalogWithListener.tableExists(ExternalCatalogWithListener.scala:142)\n  at org.apache.spark.sql.catalyst.catalog.SessionCatalog.tableExists(SessionCatalog.scala:420)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.isRunningDirectlyOnFiles(Analyzer.scala:764)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:697)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:729)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:722)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\n  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:89)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:329)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:327)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:329)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:327)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:329)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:327)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:722)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:668)\n  at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:90)\n  at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:87)\n  at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)\n  at scala.collection.immutable.List.foldLeft(List.scala:84)\n  at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:87)\n  at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:79)\n  at scala.collection.immutable.List.foreach(List.scala:392)\n  at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:79)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:143)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$execute$1.apply(Analyzer.scala:135)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$execute$1.apply(Analyzer.scala:135)\n  at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withLocalMetrics(Analyzer.scala:96)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:134)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:118)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:117)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:117)\n  at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\n  at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\n  at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\n  at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\n  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:643)\n  ... 50 elided\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to fetch table dl_tpc_item. Insufficient Lake Formation permission(s) on dl_tpc_item (Service: AWSGlue; Status Code: 400; Error Code: AccessDeniedException; Request ID: d22c3162-f033-4ccb-bc9e-7ded70c67987)\n  at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:1124)\n  at org.apache.spark.sql.hive.client.HiveClientImpl.org$apache$spark$sql$hive$client$HiveClientImpl$$getRawTableOption(HiveClientImpl.scala:357)\n  at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$tableExists$1.apply$mcZ$sp(HiveClientImpl.scala:361)\n  at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$tableExists$1.apply(HiveClientImpl.scala:361)\n  at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$tableExists$1.apply(HiveClientImpl.scala:361)\n  at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$withHiveState$1.apply(HiveClientImpl.scala:275)\n  at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:213)\n  at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:212)\n  at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:258)\n  at org.apache.spark.sql.hive.client.HiveClientImpl.tableExists(HiveClientImpl.scala:360)\n  at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$tableExists$1.apply$mcZ$sp(HiveExternalCatalog.scala:825)\n  at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$tableExists$1.apply(HiveExternalCatalog.scala:825)\n  at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$tableExists$1.apply(HiveExternalCatalog.scala:825)\n  at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:97)\n  ... 119 more\nCaused by: org.apache.hadoop.hive.metastore.api.MetaException: Insufficient Lake Formation permission(s) on dl_tpc_item (Service: AWSGlue; Status Code: 400; Error Code: AccessDeniedException; Request ID: d22c3162-f033-4ccb-bc9e-7ded70c67987)\n  at com.amazonaws.glue.catalog.converters.CatalogToHiveConverter.getHiveException(CatalogToHiveConverter.java:100)\n  at com.amazonaws.glue.catalog.converters.CatalogToHiveConverter.wrapInHiveException(CatalogToHiveConverter.java:88)\n  at com.amazonaws.glue.catalog.metastore.GlueMetastoreClientDelegate.getTable(GlueMetastoreClientDelegate.java:425)\n  at com.amazonaws.glue.catalog.metastore.AWSCatalogMetastoreClient.getTable(AWSCatalogMetastoreClient.java:968)\n  at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:1116)\n  ... 132 more\n"}]},"apps":[],"jobName":"paragraph_1581368979380_-757536926","id":"20200210-210939_888909168","dateCreated":"2020-02-10T21:09:39+0000","dateStarted":"2020-02-11T13:47:48+0000","dateFinished":"2020-02-11T13:47:49+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:3472"},{"text":"For dl_tpc_customer table we only give SELECT permission at four columns COLUMN which includes ( c_first_sales_date_sk, c_first_name,c_last_name,c_first_shipto_date_sk ) \nfollowing query should only show those columns for which user has access.\n","user":"smunigati","dateUpdated":"2020-02-12T21:42:25+0000","config":{"colWidth":12,"fontSize":9,"enabled":false,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1581543705781_975694365","id":"20200212-214145_449414646","dateCreated":"2020-02-12T21:41:45+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:3473"},{"text":"spark.sql(\"select * from tpc.dl_tpc_customer limit 10\").show()\n","user":"smunigati","dateUpdated":"2020-02-11T13:54:46+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------------------+------------+-----------+----------------------+\n|c_first_sales_date_sk|c_first_name|c_last_name|c_first_shipto_date_sk|\n+---------------------+------------+-----------+----------------------+\n|                 null|        null|       null|               2449597|\n|              2452077|       Joyce|     Deaton|                  null|\n|              2450637|       Ellis|        Dow|               2450667|\n|              2452342|        null|       Cass|               2452372|\n|                 null|        null|      Lange|                  null|\n|                 null|        Rene| Mclaughlin|                  null|\n|                 null|       Megan|      Sisco|                  null|\n|                 null|        null|       Soto|                  null|\n|                 null|      Stella|       null|               2449664|\n|              2449021|      Wesley|     Harris|                  null|\n+---------------------+------------+-----------+----------------------+"},{"type":"HTML","data":"<hr/>Spark Application Id: application_1581349405431_0003<br/>Spark WebUI: <a href=\"http://ip-10-0-1-103.ec2.internal:20888/proxy/application_1581349405431_0003/\">http://ip-10-0-1-103.ec2.internal:20888/proxy/application_1581349405431_0003/</a>"}]},"apps":[],"jobName":"paragraph_1581369082048_-880123920","id":"20200210-211122_557582954","dateCreated":"2020-02-10T21:11:22+0000","dateStarted":"2020-02-11T13:54:46+0000","dateFinished":"2020-02-11T13:54:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3474"},{"user":"smunigati","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1581429286512_-1293909854","id":"20200211-135446_1452608321","dateCreated":"2020-02-11T13:54:46+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:3475"}],"name":"LF-EMR-Zeppelin","id":"2F2SNVMGD","noteParams":{},"noteForms":{},"angularObjects":{"livy:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}